{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "8431a13e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def learning( userid, dataset):\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    import gc\n",
    "\n",
    "    import matplotlib.pyplot as plt\n",
    "    import seaborn as sns\n",
    "    %matplotlib inline\n",
    "\n",
    "    from sklearn import model_selection\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    from sklearn.preprocessing import RobustScaler\n",
    "\n",
    "    import lightgbm as lgb\n",
    "    import xgboost as xgb\n",
    "    from catboost import CatBoostRegressor\n",
    "    from catboost import CatBoostClassifier\n",
    "\n",
    "    from IPython.display import display # Allows the use of display() for DataFrames\n",
    "\n",
    "    import warnings\n",
    "    warnings.filterwarnings('ignore')\n",
    "    try:\n",
    "        data = pd.read_csv(dataset,sep=\";\", columns=['timestamp','wind_speed','active_power'])\n",
    "    except:\n",
    "        try:\n",
    "            data = pd.read_excel(dataset, columns=['timestamp','wind_speed','active_power'])\n",
    "        except:\n",
    "            TypeError(\"Неправильный формат файла.\")\n",
    "    data=data.dropna()\n",
    "    data=data.drop(['timestamp'], axis=1)\n",
    "    X = data.drop('active_power', axis=1)\n",
    "    y = data['active_power']\n",
    "    main = 'active_power'\n",
    "    n = 50\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    dev_X, val_X, dev_y, val_y = train_test_split(X_train, y_train, test_size = 0.2, random_state = 42)\n",
    "    y_test.index=list(range(len(y_test.index)))\n",
    "    def run_lgb(train_X, train_y, val_X, val_y, test_X):\n",
    "        params = {\n",
    "            \"objective\" : \"regression\",\n",
    "            \"metric\" : \"rmse\",\n",
    "            \"num_leaves\" : 40,\n",
    "            \"learning_rate\" : 0.004,\n",
    "            \"bagging_fraction\" : 0.6,\n",
    "            \"feature_fraction\" : 0.6,\n",
    "            \"bagging_frequency\" : 6,\n",
    "            \"bagging_seed\" : 42,\n",
    "            \"verbosity\" : -1,\n",
    "            \"seed\": 42\n",
    "        }\n",
    "\n",
    "        lgtrain = lgb.Dataset(train_X, label=train_y)\n",
    "        lgval = lgb.Dataset(val_X, label=val_y)\n",
    "        evals_result = {}\n",
    "        model = lgb.train(params, lgtrain, 5000, \n",
    "                          valid_sets=[lgtrain, lgval], \n",
    "                          )\n",
    "\n",
    "        pred_test_y = np.array(model.predict(test_X, num_iteration=model.best_iteration))\n",
    "        return pred_test_y, model, evals_result\n",
    "    def run_xgb(train_X, train_y, val_X, val_y, test_X):\n",
    "        params = {'objective': 'reg:linear', \n",
    "              'eval_metric': 'rmse',\n",
    "              'eta': 0.001,\n",
    "              'max_depth': 10, \n",
    "              'subsample': 0.6, \n",
    "              'colsample_bytree': 0.6,\n",
    "              'alpha':0.001,\n",
    "              'random_state': 42, \n",
    "              'silent': True}\n",
    "\n",
    "        tr_data = xgb.DMatrix(train_X, train_y)\n",
    "        va_data = xgb.DMatrix(val_X, val_y)\n",
    "\n",
    "        watchlist = [(tr_data, 'train'), (va_data, 'valid')]\n",
    "\n",
    "        model_xgb = xgb.train(params, tr_data, 2000, watchlist, maximize=False, early_stopping_rounds = 100, verbose_eval=100)\n",
    "\n",
    "        dtest = xgb.DMatrix(test_X)\n",
    "        xgb_pred_y = np.array(model_xgb.predict(dtest))\n",
    "\n",
    "        return xgb_pred_y, model_xgb\n",
    "    def run_cat(dev_X, dev_y, val_X, val_y, X_test):\n",
    "        cb_model = CatBoostRegressor(iterations=500,\n",
    "                                 learning_rate=0.05,\n",
    "                                 depth=10,\n",
    "                                 eval_metric='RMSE',\n",
    "                                 random_seed = 42,\n",
    "                                 bagging_temperature = 0.2,\n",
    "                                 od_type='Iter',\n",
    "                                 metric_period = 50,\n",
    "                                 od_wait=20)\n",
    "        cb_model.fit(dev_X, dev_y,\n",
    "                 eval_set=(val_X, val_y),\n",
    "                 use_best_model=True,\n",
    "                 verbose=50)\n",
    "        pred_test_cat = np.array(cb_model.predict(X_test))\n",
    "        return pred_test_cat, cb_model\n",
    "    pred_test, model, evals_result = run_lgb(dev_X, dev_y, val_X, val_y, X_test)\n",
    "    pred_test_cat, model_cat = run_cat(dev_X, dev_y, val_X, val_y, X_test)\n",
    "    pred_test_xgb, model_xgb = run_xgb(dev_X, dev_y, val_X, val_y, X_test)\n",
    "    import pickle\n",
    "    for i in ['model_xgb','model', 'model_cat']:\n",
    "        with open(f'{userid}_{i}.pkl','wb') as f:\n",
    "            exec(f\"clf = {i}\")\n",
    "            pickle.dump(clf,f)\n",
    "\n",
    "\n",
    "    from keras.models import Sequential\n",
    "    from keras.layers import LSTM\n",
    "    from keras.layers import Dense\n",
    "    from keras.layers import SimpleRNN\n",
    "    from keras.layers import Dropout\n",
    "    from keras.layers import GRU, Bidirectional\n",
    "    from keras.optimizers.legacy import SGD\n",
    "    import math\n",
    "\n",
    "    from sklearn import metrics\n",
    "    from sklearn.metrics import mean_squared_error\n",
    "    def convert(data, main, n=50):\n",
    "        training_data_len = math.ceil(len(data) * .8)\n",
    "        train_data = data[:training_data_len].iloc[:,:] \n",
    "        test_data = data[training_data_len:].iloc[:,:]\n",
    "        dataset_train = train_data[main].values \n",
    "        # Reshaping 1D to 2D array\n",
    "        dataset_train = np.reshape(dataset_train, (-1,1)) \n",
    "        dataset_train.shape\n",
    "        from sklearn.preprocessing import MinMaxScaler\n",
    "        scaler = MinMaxScaler(feature_range=(0,1))\n",
    "        # scaling dataset\n",
    "        scaled_train = scaler.fit_transform(dataset_train)\n",
    "        # Selecting Open Price values\n",
    "        dataset_test = test_data[main].values \n",
    "        # Reshaping 1D to 2D array\n",
    "        dataset_test = np.reshape(dataset_test, (-1,1))  \n",
    "        # Normalizing values between 0 and 1\n",
    "        scaled_test = scaler.fit_transform(dataset_test)\n",
    "        X_train = []\n",
    "        y_train = []\n",
    "        for i in range(n, len(scaled_train)):\n",
    "            X_train.append(scaled_train[i-n:i, 0])\n",
    "            y_train.append(scaled_train[i-11:i+1, 0])\n",
    "        X_test = []\n",
    "        y_test = []\n",
    "        # TODO y_test and y_train for 12 points\n",
    "        # TODO rewrite for loop, to not get out of the scope error\n",
    "        for i in range(n, len(scaled_test)):\n",
    "            X_test.append(scaled_test[i-n:i, 0])\n",
    "            y_test.append(scaled_test[i-11:i+1, 0])\n",
    "        X_train, y_train = np.array(X_train), np.array(y_train)\n",
    "\n",
    "        #Reshaping\n",
    "        X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1],1))\n",
    "    #     y_train = np.reshape(y_train, (y_train.shape[0],y_train))\n",
    "        X_test, y_test = np.array(X_test), np.array(y_test)\n",
    "\n",
    "        #Reshaping\n",
    "        X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1],1))\n",
    "    #     y_test = np.reshape(y_test, (y_test.shape[0],1))    \n",
    "        return X_train, y_train, X_test, y_test,train_data, test_data, scaler\n",
    "    def all_model(X_train,y_train):    \n",
    "        regressor = Sequential()\n",
    "\n",
    "        # adding RNN layers and dropout regularization\n",
    "        regressor.add(SimpleRNN(units = 12, \n",
    "                                activation = \"tanh\",\n",
    "                                return_sequences = True,\n",
    "                                input_shape = (X_train.shape[1],1)))\n",
    "        regressor.add(Dropout(0.2))\n",
    "\n",
    "        regressor.add(SimpleRNN(units = 12, \n",
    "                                activation = \"tanh\",\n",
    "                                return_sequences = True))\n",
    "\n",
    "        regressor.add(SimpleRNN(units = 12,\n",
    "                                activation = \"tanh\",\n",
    "                                return_sequences = True))\n",
    "\n",
    "        regressor.add( SimpleRNN(units = 12))\n",
    "\n",
    "        # adding the output layer\n",
    "        regressor.add(Dense(units = 12,activation='sigmoid'))\n",
    "\n",
    "        # compiling RNN\n",
    "        regressor.compile(optimizer = SGD(learning_rate=0.01,\n",
    "                                          decay=1e-6, \n",
    "                                          momentum=0.9, \n",
    "                                          nesterov=True), \n",
    "                          loss = \"mean_squared_error\")\n",
    "\n",
    "        regressor.summary()\n",
    "\n",
    "        return regressor\n",
    "    X_train, y_train, X_test, y_test, test_data, train_data, scaler = convert(data, main, n)\n",
    "    regressor = all_model(X_train,y_train)   \n",
    "    regressor.fit(X_train,y_train,epochs=20,batch_size=200)\n",
    "    import pickle\n",
    "    for i in ['regressor']:\n",
    "        with open(f'{userid}_{i}.pkl','wb') as f:\n",
    "            exec(f\"clf = {i}\")\n",
    "            pickle.dump(clf,f)\n",
    "    last = X_test[0]\n",
    "    with open(f'{userid}_last.npy', 'wb') as f:\n",
    "        np.save(f, last)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "ee6970b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction_with(userid, town):\n",
    "    for i in ['model_xgb','model', 'model_cat']:\n",
    "    with open(f'{userid}_{i}.pkl', \"rb\") as file:\n",
    "        deserialized_data = pickle.load(file)\n",
    "        exec(f\"{i} = deserialized_data\")\n",
    "    import asyncio\n",
    "    import aiohttp\n",
    "    from bs4 import BeautifulSoup as BS\n",
    "    from fake_useragent import UserAgent\n",
    "\n",
    "    import asyncio\n",
    "    import aiohttp\n",
    "    from bs4 import BeautifulSoup as BS\n",
    "    from fake_useragent import UserAgent\n",
    "    from datetime import datetime as dt\n",
    "    import json\n",
    "    import os\n",
    "    import random\n",
    "    import re\n",
    "    import time\n",
    "    import requests\n",
    "    from bs4 import BeautifulSoup\n",
    "    import pandas as pd\n",
    "    def get_data_forecast(url):\n",
    "\n",
    "            headers = {\"User-Agent\": UserAgent().random}\n",
    "            req = requests.get(url, headers)\n",
    "            soup = BeautifulSoup(req.text, \"lxml\")\n",
    "            week = soup.find_all(\"div\",class_=\"p-flex p-flex_content_justify margin_bottom_20\")\n",
    "            l_wind, l_days = [],[]\n",
    "            for i in range(56):\n",
    "                l_days.append(dt.now()+timedelta(hours=6)-timedelta(hours = dt.now().hour, minutes=dt.now().minute))\n",
    "            for w in week:     \n",
    "                days=w.find_all(\"div\",class_=\"p-flex__column p-flex__column_percent-16\")   \n",
    "                for d in days:\n",
    "                    feat = d.find_all(\"span\", class_=\"link__text\")\n",
    "                    l_wind.append(int(feat[2].text[:1]))\n",
    "\n",
    "            df = pd.DataFrame({'timestamp': l_days,\n",
    "                               'wind_speed':l_wind\n",
    "            })\n",
    "            return df\n",
    "\n",
    "    df = (get_data_forecast(f\"https://pogoda.mail.ru/prognoz/{town.lower()}/14dney/\"))\n",
    "    X =data.drop(['timestamp'], axis=1)\n",
    "    pred_test = np.array(model.predict(X))\n",
    "    pred_test_cat = np.array(model_xgb.predict(X))\n",
    "    pred_test_xgb = np.array(cb_model.predict(X))\n",
    "    def total_predict(pred_test,pred_test_xgb,pred_test_cat):\n",
    "        sub = pd.DataFrame()\n",
    "        sub_lgb = pd.DataFrame()\n",
    "        sub_lgb[\"energy\"] = pred_test\n",
    "\n",
    "        sub_xgb = pd.DataFrame()\n",
    "        sub_xgb[\"energy\"] = pred_test_xgb\n",
    "\n",
    "        sub_cat = pd.DataFrame()\n",
    "        sub_cat[\"energy\"] = pred_test_cat\n",
    "\n",
    "        sub[\"energy\"] = (sub_lgb[\"energy\"] * 0.5 + sub_xgb[\"energy\"] * 0.3 + sub_cat[\"energy\"] * 0.2)\n",
    "        return sub[\"energy\"]\n",
    "    total = total_predict(pred_test,pred_test_xgb,pred_test_cat)\n",
    "    def plotting(y_test, pred_test):\n",
    "        fig, axs = plt.subplots()\n",
    "        #Plot for LightGBM predictions\n",
    "        axs.plot( y_test, label = \"test_data\", color = \"b\")\n",
    "        axs.plot(pred_test, label = \"prediction \", color = \"g\")\n",
    "        plt.ylabel('kWt')\n",
    "        axs.legend()\n",
    "        plt.savefig(f\"{userid}_plot.png\")\n",
    "    plotting(y_test, total)\n",
    "    df['active_power'] = total\n",
    "    df.to_csv(f\"{userid}_data.csv\")\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "b25c2a40",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction_without(userid):\n",
    "    with open(f'{userid}_last.npy', 'rb') as f:\n",
    "        last = np.load(f)\n",
    "    for i in ['regressor']:\n",
    "        with open(f'{userid}_{i}.pkl', \"rb\") as file:\n",
    "            deserialized_data = pickle.load(file)\n",
    "            exec(f\"{i} = deserialized_data\")\n",
    "    def predict_row(X_test):\n",
    "        y_RNN = regressor.predict(X_test)\n",
    "        # scaling back from 0-1 to original\n",
    "        y_RNN_O = scaler.inverse_transform(y_RNN) \n",
    "        return y_RNN_O \n",
    "    def plotting_row(test_data):\n",
    "        fig = plt.subplots()\n",
    "\n",
    "        #Plot for RNN predictions\n",
    "        plt.plot(np.arange(test_data.index[-1]+1,test_data.index[-1]+13) , y_RNN_O[-1].reshape((12,1)), label = \"y_RNN\", color = \"red\", alpha=0.75)\n",
    "        plt.title(\"Prediction of time row\")\n",
    "        plt.xlabel(\"Days\")\n",
    "        plt.ylabel(\"Wt\")\n",
    "        plt.show()  \n",
    "        plt.savefig(f\"{userid}_plot.png\")\n",
    "    y_RNN_O  = predict_row(last)\n",
    "    plotting_row(test_data)\n",
    "    l_days = []\n",
    "    for i in range(12):\n",
    "        l_days.append(dt.now()+timedelta(hours=6)-timedelta(hours = dt.now().hour, minutes=dt.now().minute))\n",
    "    df = pd.DataFrame({'timestamp': l_days,\n",
    "                               'active_power':y_RNN_O[-1]\n",
    "            })\n",
    "    df.to_csv(f'{userid}_data.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
